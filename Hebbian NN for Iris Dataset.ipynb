{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f609d2-1e5c-459a-b9ae-c24677125cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2522\n",
      "Epoch 2, Loss: 0.2547\n",
      "Epoch 3, Loss: 0.2600\n",
      "Epoch 4, Loss: 0.2717\n",
      "Epoch 5, Loss: 0.2977\n",
      "Epoch 6, Loss: 0.3480\n",
      "Epoch 7, Loss: 0.4107\n",
      "Epoch 8, Loss: 0.4629\n",
      "Epoch 9, Loss: 0.5056\n",
      "Epoch 10, Loss: 0.5372\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Step 1: Define activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Step 2: Define loss function\n",
    "def loss_function(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Step 3: Implement Hebbian Neural Network class\n",
    "class HebbianNN:\n",
    "    def __init__(self, input_size, output_size, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Initializes the network with random weights.\n",
    "        :param input_size: Number of input features\n",
    "        :param output_size: Number of output neurons\n",
    "        :param learning_rate: Learning rate for weight updates\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(input_size, output_size) * 0.01\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        :param X: Input data\n",
    "        :return: Output after applying activation function\n",
    "        \"\"\"\n",
    "        self.input = X\n",
    "        self.output = sigmoid(np.dot(X, self.weights))\n",
    "        return self.output\n",
    "    \n",
    "    def hebbian_update(self):\n",
    "        \"\"\"\n",
    "        Updates the weights using Hebbian learning rule.\n",
    "        \"\"\"\n",
    "        self.weights += self.learning_rate * np.dot(self.input.T, self.output)\n",
    "    \n",
    "    def train(self, X, y, epochs=100):\n",
    "        \"\"\"\n",
    "        Trains the network using the given dataset.\n",
    "        :param X: Feature matrix\n",
    "        :param y: Target matrix\n",
    "        :param epochs: Number of iterations for training\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = loss_function(y, y_pred)\n",
    "            self.hebbian_update()\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Step 4: Load and preprocess the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data  # Extract features\n",
    "y = data.target.reshape(-1, 1)  # Reshape target values for encoding\n",
    "\n",
    "# One-hot encode target values\n",
    "encoder = OneHotEncoder(sparse_output =False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Standardize features for better performance\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 5: Train the Hebbian Neural Network\n",
    "nn = HebbianNN(input_size=X.shape[1], output_size=y.shape[1], learning_rate=0.01)\n",
    "nn.train(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd13a00-6958-4913-bc80-9d4797bd8f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
